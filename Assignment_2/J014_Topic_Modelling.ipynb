{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J014_Topic_Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTi_tVbFXSZ6",
        "outputId": "047493ff-5ca0-4d82-91e6-7fd388944f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/gdrive/MyDrive/Semester 6/NLP/papers.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "hnZ3BMzGYG5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "7a9694c1-0eee-4a81-a426-bced208b5784"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d4936852-1f2e-4656-b49c-27bb6f0f0ae9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4936852-1f2e-4656-b49c-27bb6f0f0ae9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4936852-1f2e-4656-b49c-27bb6f0f0ae9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4936852-1f2e-4656-b49c-27bb6f0f0ae9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AQ9id6FmtCw",
        "outputId": "5578309b-6da0-4d25-a416-78a4c4e9cc32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7241 entries, 0 to 7240\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          7241 non-null   int64 \n",
            " 1   year        7241 non-null   int64 \n",
            " 2   title       7241 non-null   object\n",
            " 3   event_type  2422 non-null   object\n",
            " 4   pdf_name    7241 non-null   object\n",
            " 5   abstract    7241 non-null   object\n",
            " 6   paper_text  7241 non-null   object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 396.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data['paper_text']"
      ],
      "metadata": {
        "id": "UeQ7t9R5nj9R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "faW_W6cslJFT",
        "outputId": "9d731745-ca3b-4b39-e9f8-25a1b5e04fbf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABASE\\nAND ITS APPLICATIONS\\nHisashi Suzuki and Suguru Arimoto\\nOsaka University, Toyonaka, Osaka 560, Japan\\nABSTRACT\\nAn efficient method of self-organizing associative databases is proposed together with\\napplications to robot eyesight systems. The proposed databases can associate any input\\nwith some output. In the first half part of discussion, an algorithm of self-organization is\\nproposed. From an aspect of hardware, it produces a new style of neural network. In the\\nlatter half part, an applicability to handwritten letter recognition and that to an autonomous\\nmobile robot system are demonstrated.\\n\\nINTRODUCTION\\nLet a mapping f : X -+ Y be given. Here, X is a finite or infinite set, and Y is another\\nfinite or infinite set. A learning machine observes any set of pairs (x, y) sampled randomly\\nfrom X x Y. (X x Y means the Cartesian product of X and Y.) And, it computes some\\nestimate j : X -+ Y of f to make small, the estimation error in some measure.\\nUsually we say that: the faster the decrease of estimation error with increase of the number of samples, the better the learning machine. However, such expression on performance\\nis incomplete. Since, it lacks consideration on the candidates of J of j assumed preliminarily. Then, how should we find out good learning machines? To clarify this conception,\\nlet us discuss for a while on some types of learning machines. And, let us advance the\\nunderstanding of the self-organization of associative database .\\n. Parameter Type\\nAn ordinary type of learning machine assumes an equation relating x\\'s and y\\'s with\\nparameters being indefinite, namely, a structure of f. It is equivalent to define implicitly a\\nset F of candidates of\\n(F is some subset of mappings from X to Y.) And, it computes\\nvalues of the parameters based on the observed samples. We call such type a parameter\\ntype.\\nFor a learning machine defined well, if F 3 f, j approaches f as the number of samples\\nincreases. In the alternative case, however, some estimation error remains eternally. Thus,\\na problem of designing a learning machine returns to find out a proper structure of f in this\\nsense.\\nOn the other hand, the assumed structure of f is demanded to be as compact as possible\\nto achieve a fast learning. In other words, the number of parameters should be small. Since,\\nif the parameters are few, some j can be uniquely determined even though the observed\\nsamples are few. However, this demand of being proper contradicts to that of being compact.\\nConsequently, in the parameter type, the better the compactness of the assumed structure\\nthat is proper, the better the learning machine. This is the most elementary conception\\nwhen we design learning machines .\\n\\n1.\\n\\n. Universality and Ordinary Neural Networks\\nNow suppose that a sufficient knowledge on f is given though J itself is unknown. In\\nthis case, it is comparatively easy to find out proper and compact structures of J. In the\\nalternative case, however, it is sometimes difficult. A possible solution is to give up the\\ncompactness and assume an almighty structure that can cover various 1\\'s. A combination\\nof some orthogonal bases of the infinite dimension is such a structure. Neural networks 1 ,2\\nare its approximations obtained by truncating finitely the dimension for implementation.\\n\\n? American Institute of Physics 1988\\n\\n\\x0c768\\nA main topic in designing neural networks is to establish such desirable structures of 1.\\nThis work includes developing practical procedures that compute values of coefficients from\\nthe observed samples. Such discussions are :flourishing since 1980 while many efficient methods have been proposed. Recently, even hardware units computing coefficients in parallel\\nfor speed-up are sold, e.g., ANZA, Mark III, Odyssey and E-1.\\nNevertheless, in neural networks, there always exists a danger of some error remaining\\neternally in estimating /. Precisely speaking, suppose that a combination of the bases of a\\nfinite number can define a structure of 1 essentially. In other words, suppose that F 3 /, or\\n1 is located near F. In such case, the estimation error is none or negligible. However, if 1\\nis distant from F, the estimation error never becomes negligible. Indeed, many researches\\nreport that the following situation appears when 1 is too complex. Once the estimation\\nerror converges to some value (> 0) as the number of samples increases, it decreases hardly\\neven though the dimension is heighten. This property sometimes is a considerable defect of\\nneural networks .\\n. Recursi ve Type\\nThe recursive type is founded on another methodology of learning that should be as\\nfollows. At the initial stage of no sample, the set Fa (instead of notation F) of candidates\\nof I equals to the set of all mappings from X to Y. After observing the first sample\\n(Xl, Yl) E X x Y, Fa is reduced to Fi so that I(xt) = Yl for any I E F. After observing\\nthe second sample (X2\\' Y2) E X x Y, Fl is further reduced to F2 so that i(xt) = Yl and\\nI(X2) = Y2 for any I E F. Thus, the candidate set F becomes gradually small as observation\\nof samples proceeds. The after observing i-samples, which we write\\nis one of the most\\nlikelihood estimation of 1 selected in fi;. Hence, contrarily to the parameter type, the\\nrecursive type guarantees surely that j approaches to 1 as the number of samples increases.\\nThe recursive type, if observes a sample (x\" yd, rewrites values 1,-l(X),S to I,(x)\\'s for\\nsome x\\'s correlated to the sample. Hence, this type has an architecture composed of a rule\\nfor rewriting and a free memory space. Such architecture forms naturally a kind of database\\nthat builds up management systems of data in a self-organizing way. However, this database\\ndiffers from ordinary ones in the following sense. It does not only record the samples already\\nobserved, but computes some estimation of l(x) for any x E X. We call such database an\\nassociative database.\\nThe first subject in constructing associative databases is how we establish the rule for\\nrewri ting. For this purpose, we adap t a measure called the dissimilari ty. Here, a dissimilari ty\\nmeans a mapping d : X x X -+ {reals > O} such that for any (x, x) E X x X, d(x, x) > 0\\nwhenever l(x) t /(x). However, it is not necessarily defined with a single formula. It is\\ndefinable with, for example, a collection of rules written in forms of \"if? .. then?? .. \"\\nThe dissimilarity d defines a structure of 1 locally in X x Y. Hence, even though\\nthe knowledge on f is imperfect, we can re:flect it on d in some heuristic way. Hence,\\ncontrarily to neural networks, it is possible to accelerate the speed of learning by establishing\\nd well. Especially, we can easily find out simple d\\'s for those l\\'s which process analogically\\ninformation like a human. (See the applications in this paper.) And, for such /\\'s, the\\nrecursive type shows strongly its effectiveness.\\nWe denote a sequence of observed samples by (Xl, Yd, (X2\\' Y2),???. One of the simplest\\nconstructions of associative databases after observing i-samples (i = 1,2,.,,) is as follows.\\n\\ni\\n\\ni\"\\n\\nI,\\n\\nAlgorithm 1. At the initial stage, let So be the empty set. For every i =\\n1,2\" .. , let i,-l(x) for any x E X equal some y* such that (x*,y*) E S,-l and\\n\\nd(x, x*) =\\n\\nmin\\n(%,y)ES.-t\\n\\nd(x, x) .\\n\\nFurthermore, add (x\" y,) to S;-l to produce Sa, i.e., S, = S,_l U {(x\"\\n\\n(1)\\n\\ny,n.\\n\\n\\x0c769\\n\\nAnother version improved to economize the memory is as follows.\\n\\nAlgorithm 2, At the initial stage, let So be composed of an arbitrary element\\nin X x Y. For every i = 1,2\"\", let ii-lex) for any x E X equal some y. such\\nthat (x?, y.) E Si-l and\\nd(x, x?) =\\n\\nmin\\n\\nd(x, x) .\\n\\n(i,i)ES.-l\\n\\nFurthermore, if ii-l(Xi) # Yi then let Si = Si-l, or add (Xi, Yi) to Si-l to\\nproduce Si, i.e., Si = Si-l U {(Xi, Yi)}\\'\\nIn either construction, ii approaches to f as i increases. However, the computation time\\ngrows proportionally to the size of Si. The second subject in constructing associative\\ndatabases is what addressing rule we should employ to economize the computation time. In\\nthe subsequent chapters, a construction of associative database for this purpose is proposed.\\nIt manages data in a form of binary tree.\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABASE\\nGiven a sample sequence (Xl, Yl), (X2\\' Y2), .. \" the algorithm for constructing associative\\ndatabase is as follows.\\n\\nAlgorithm 3,\\'\\n\\nStep I(Initialization): Let (x[root], y[root]) = (Xl, Yd. Here, x[.] and y[.] are\\nvariables assigned for respective nodes to memorize data.. Furthermore, let t = 1.\\nStep 2: Increase t by 1, and put x, in. After reset a pointer n to the root, repeat\\nthe following until n arrives at some terminal node, i.e., leaf.\\nNotations nand\\nd(xt, x[n)), let n\\n\\nn mean the descendant nodes of n.\\n=n. Otherwise, let n =n.\\n\\nIf d(x\" r[n)) ~\\n\\nStep 3: Display yIn] as the related information. Next, put y, in. If yIn] = y\" back\\nto step 2. Otherwise, first establish new descendant nodes n and n. Secondly,\\nlet\\n\\n(x[n], yIn))\\n(x[n], yIn))\\n\\n(x[n], yIn)),\\n(Xt, y,).\\n\\n(2)\\n(3)\\n\\nFinally, back to step 2. Here, the loop of step 2-3 can be stopped at any time\\nand also can be continued.\\nNow, suppose that gate elements, namely, artificial \"synapses\" that play the role of branching by d are prepared. Then, we obtain a new style of neural network with gate elements\\nbeing randomly connected by this algorithm.\\n\\nLETTER RECOGNITION\\nRecen tly, the vertical slitting method for recognizing typographic English letters3 , the\\nelastic matching method for recognizing hand written discrete English letters4 , the global\\ntraining and fuzzy logic search method for recognizing Chinese characters written in square\\nstyleS, etc. are published. The self-organization of associative database realizes the recognition of handwritten continuous English letters.\\n\\n\\x0c770\\n\\n9 /wn\"\\n\\nNOV\\n\\n~ ~ ~ -xk :La.t\\n\\n~~ ~ ~~~\\n\\ndw1lo\\'\\n\\n~~~~~of~~\\n\\n~~~ 4,-?~~4Fig. 1. Source document.\\n2~~---------------\\'\\n\\nlOO~---------------\\'\\n\\nH\\n\\no\\n\\no\\nFig. 2. Windowing.\\n\\n1000\\n\\n2000\\n\\n3000\\n\\n4000\\n\\nNumber of samples\\n\\no\\n\\n1000\\n\\n2000\\n\\n3000\\n\\n4000\\n\\nNUAlber of sampl es\\n\\nFig. 3. An experiment result.\\n\\nAn image scanner takes a document image (Fig. 1). The letter recognizer uses a parallelogram window that at least can cover the maximal letter (Fig. 2), and processes the\\nsequence of letters while shifting the window. That is, the recognizer scans a word in a\\nslant direction. And, it places the window so that its left vicinity may be on the first black\\npoint detected. Then, the window catches a letter and some part of the succeeding letter.\\nIf recognition of the head letter is performed, its end position, namely, the boundary line\\nbetween two letters becomes known. Hence, by starting the scanning from this boundary\\nand repeating the above operations, the recognizer accomplishes recursively the task. Thus\\nthe major problem comes to identifying the head letter in the window.\\nConsidering it, we define the following.\\n? Regard window images as x\\'s, and define X accordingly.\\n? For a (x, x) E X x X, denote by B a black point in the left area from the boundary on\\nwindow image X. Project each B onto window image x. Then, measure the Euclidean\\ndistance 6 between fj and a black point B on x being the closest to B. Let d(x, x) be\\nthe summation of 6\\'s for all black points B\\'s on x divided by the number of B\\'s.\\n? Regard couples of the \"reading\" and the position of boundary as y\\'s, and define Y\\naccordingly.\\nAn operator teaches the recognizer in interaction the relation between window image and\\nreading& boundary with algorithm 3. Precisely, if the recalled reading is incorrect, the\\noperator teaches a correct reading via the console. Moreover, if the boundary position is\\nincorrect, he teaches a correct position via the mouse.\\nFig. 1 shows partially a document image used in this experiment. Fig. 3 shows the\\nchange of the number of nodes and that of the recognition rate defined as the relative\\nfrequency of correct answers in the past 1000 trials. Speciiications of the window are height\\n= 20dot, width = 10dot, and slant angular = 68deg. In this example, the levels of tree\\nwere distributed in 6-19 at time 4000 and the recognition rate converged to about 74%.\\nExperimentally, the recognition rate converges to about 60-85% in most cases, and to 95% at\\na rare case. However, it does not attain 100% since, e.g., \"c\" and \"e\" are not distinguishable\\nbecause of excessive lluctuation in writing. If the consistency of the x, y-relation is not\\nassured like this, the number of nodes increases endlessly (d. Fig. 3). Hence, it is clever to\\nstop the learning when the recognition rate attains some upper limit. To improve further\\nthe recognition rate, we must consider the spelling of words. It is one of future subjects.\\n\\n\\x0c771\\n\\nOBSTACLE AVOIDING MOVEMENT\\nVarious systems of camera type autonomous mobile robot are reported flourishingly6-1O.\\nThe system made up by the authors (Fig. 4) also belongs to this category. Now, in mathematical methodologies, we solve usually the problem of obstacle avoiding movement as\\na cost minimization problem under some cost criterion established artificially. Contrarily,\\nthe self-organization of associative database reproduces faithfully the cost criterion of an\\noperator. Therefore, motion of the robot after learning becomes very natural.\\nNow, the length, width and height of the robot are all about O.7m, and the weight is\\nabout 30kg. The visual angle of camera is about 55deg. The robot has the following three\\nfactors of motion. It turns less than ?30deg, advances less than 1m, and controls speed less\\nthan 3km/h. The experiment was done on the passageway of wid th 2.5m inside a building\\nwhich the authors\\' laboratories exist in (Fig. 5). Because of an experimental intention, we\\narrange boxes, smoking stands, gas cylinders, stools, handcarts, etc. on the passage way at\\nrandom. We let the robot take an image through the camera, recall a similar image, and\\ntrace the route preliminarily recorded on it. For this purpose, we define the following.\\n? Let the camera face 28deg downward to take an image, and process it through a low\\npass filter. Scanning vertically the filtered image from the bottom to the top, search\\nthe first point C where the luminance changes excessively. Then, su bstitu te all points\\nfrom the bottom to C for white, and all points from C to the top for black (Fig. 6).\\n(If no obstacle exists just in front of the robot, the white area shows the \\'\\'free\\'\\' area\\nwhere the robot can move around.) Regard binary 32 x 32dot images processed thus\\nas x\\'s, and define X accordingly.\\n? For every (x, x) E X x X, let d(x, x) be the number of black points on the exclusive-or\\nimage between x and X.\\n? Regard as y\\'s the images obtained by drawing routes on images x\\'s, and define Y\\naccordingly.\\nThe robot superimposes, on the current camera image x, the route recalled for x, and\\ninquires the operator instructions. The operator judges subjectively whether the suggested\\nroute is appropriate or not. In the negative answer, he draws a desirable route on x with the\\nmouse to teach a new y to the robot. This opera.tion defines implicitly a sample sequence\\nof (x, y) reflecting the cost criterion of the operator.\\n\\n.::l\" !\\n-\\n\\nIibUBe\\n\\n_. -\\n\\n22\\n\\n11\\n\\nRoan\\n\\n12\\n\\n{-\\n\\n13\\n\\nStationary uni t\\n\\nFig. 4. Configuration of\\nautonomous mobile robot system.\\n\\n~\\n\\nI\\n\\n,\\n\\n23\\n\\n24\\n\\nNorth\\n14\\n\\nrmbi Ie unit (robot)\\n\\n-\\n\\nRoan\\n\\ny\\n\\nt\\n\\nFig. 5. Experimental\\nenvironment.\\n\\n\\x0c772\\n\\nWall\\n\\nCamera image\\n\\nPreprocessing\\n\\nA\\n\\n::: !fa\\n\\n?\\n\\nPreprocessing\\n\\n0\\n\\nO\\n\\nCourse\\nsuggest ion\\n\\n??\\n\\n..\\n\\nSearch\\n\\nA\\n\\nFig. 6. Processing for\\nobstacle avoiding movement.\\n\\nx\\n\\nFig. 1. Processing for\\nposition identification.\\nWe define the satisfaction rate by the relative frequency of acceptable suggestions of\\nroute in the past 100 trials. In a typical experiment, the change of satisfaction rate showed\\na similar tendency to Fig. 3, and it attains about 95% around time 800. Here, notice that\\nthe rest 5% does not mean directly the percentage of collision. (In practice, we prevent the\\ncollision by adopting some supplementary measure.) At time 800, the number of nodes was\\n145, and the levels of tree were distributed in 6-17.\\nThe proposed method reflects delicately various characters of operator. For example, a\\nrobot trained by an operator 0 moves slowly with enough space against obstacles while one\\ntrained by another operator 0\\' brushes quickly against obstacles. This fact gives us a hint\\non a method of printing \"characters\" into machines.\\nPOSITION IDENTIFICATION\\nThe robot can identify its position by recalling a similar landscape with the position data\\nto a camera image. For this purpose, in principle, it suffices to regard camera images and\\nposition data as x\\'s and y\\'s, respectively. However, the memory capacity is finite in actual\\ncompu ters. Hence, we cannot but compress the camera images at a slight loss of information.\\nSuch compression is admittable as long as the precision of position identification is in an\\nacceptable area. Thus, the major problem comes to find out some suitable compression\\nmethod.\\nIn the experimental environment (Fig. 5), juts are on the passageway at intervals of\\n3.6m, and each section between adjacent juts has at most one door. The robot identifies\\nroughly from a surrounding landscape which section itself places in. And, it uses temporarily\\na triangular surveying technique if an exact measure is necessary. To realize the former task,\\nwe define the following .\\n? Turn the camera to take a panorama image of 360deg. Scanning horizontally the\\ncenter line, substitute the points where the luminance excessively changes for black\\nand the other points for white (Fig. 1). Regard binary 360dot line images processed\\nthus as x\\'s, and define X accordingly.\\n? For every (x, x) E X x X, project each black point A on x onto x. And, measure the\\nEuclidean distance 6 between A and a black point A on x being the closest to A. Let\\nthe summation of 6 be S. Similarly, calculate S by exchanging the roles of x and X.\\nDenoting the numbers of A\\'s and A\\'s respectively by nand n, define\\n\\n\\x0c773\\n\\nd(x, x) =\\n\\n~(~\\n+ ~).\\n2 n\\nn\\n\\n(4)\\n\\n? Regard positive integers labeled on sections as y\\'s (cf. Fig. 5), and define Y accordingly.\\nIn the learning mode, the robot checks exactly its position with a counter that is reset periodically by the operator. The robot runs arbitrarily on the passageways within 18m area\\nand learns the relation between landscapes and position data. (Position identification beyond 18m area is achieved by crossing plural databases one another.) This task is automatic\\nexcepting the periodic reset of counter, namely, it is a kind of learning without teacher.\\nWe define the identification rate by the relative frequency of correct recalls of position\\ndata in the past 100 trials. In a typical example, it converged to about 83% around time\\n400. At time 400, the number of levels was 202, and the levels oftree were distributed in 522. Since the identification failures of 17% can be rejected by considering the trajectory, no\\npro blem arises in practical use. In order to improve the identification rate, the compression\\nratio of camera images must be loosened. Such possibility depends on improvement of the\\nhardware in the future.\\nFig. 8 shows an example of actual motion of the robot based on the database for obstacle\\navoiding movement and that for position identification. This example corresponds to a case\\nof moving from 14 to 23 in Fig. 5. Here, the time interval per frame is about 40sec.\\n\\n,~. .~ (\\n;~\"i..\\n~\\n\\n\"\\n\\n\"\\n\\n.\\n\\n..I\\n\\nI\\n\\n?\\n?\\n\\n\"\\n\\nI\\'\\n.\\n\\'.1\\nt\\n\\n;\\n\\ni\\n\\n-:\\n, . . , \\'II\\n\\nFig. 8. Actual motion of the robot.\\n\\n\\x0c774\\n\\nCONCLUSION\\nA method of self-organizing associative databases was proposed with the application to\\nrobot eyesight systems. The machine decomposes a global structure unknown into a set of\\nlocal structures known and learns universally any input-output response. This framework\\nof problem implies a wide application area other than the examples shown in this paper.\\nA defect of the algorithm 3 of self-organization is that the tree is balanced well only\\nfor a subclass of structures of f. A subject imposed us is to widen the class. A probable\\nsolution is to abolish the addressing rule depending directly on values of d and, instead, to\\nestablish another rule depending on the distribution function of values of d. It is now under\\ninvestigation.\\n\\nREFERENCES\\n1. Hopfield, J. J. and D. W. Tank, \"Computing with Neural Circuit: A Model/\\'\\n\\nScience 233 (1986), pp. 625-633.\\n2. Rumelhart, D. E. et al., \"Learning Representations by Back-Propagating Errors,\" Nature 323 (1986), pp. 533-536.\\n\\n3. Hull, J. J., \"Hypothesis Generation in a Computational Model for Visual Word\\nRecognition,\" IEEE Expert, Fall (1986), pp. 63-70.\\n4. Kurtzberg, J. M., \"Feature Analysis for Symbol Recognition by Elastic Matching,\" IBM J. Res. Develop. 31-1 (1987), pp. 91-95.\\n\\n5. Wang, Q. R. and C. Y. Suen, \"Large Tree Classifier with Heuristic Search and\\nGlobal Training,\" IEEE Trans. Pattern. Anal. & Mach. Intell. PAMI 9-1\\n(1987) pp. 91-102.\\n6. Brooks, R. A. et al, \"Self Calibration of Motion and Stereo Vision for Mobile\\nRobots,\" 4th Int. Symp. of Robotics Research (1987), pp. 267-276.\\n7. Goto, Y. and A. Stentz, \"The CMU System for Mobile Robot Navigation,\" 1987\\nIEEE Int. Conf. on Robotics & Automation (1987), pp. 99-105.\\n8. Madarasz, R. et al., \"The Design of an Autonomous Vehicle for the Disabled,\"\\nIEEE Jour. of Robotics & Automation RA 2-3 (1986), pp. 117-125.\\n9. Triendl, E. and D. J. Kriegman, \"Stereo Vision and Navigation within Buildings,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 1725-1730.\\n10. Turk, M. A. et al., \"Video Road-Following for the Autonomous Land Vehicle,\"\\n1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 273-279.\\n\\n\\x0c'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "np.random.seed(204)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0jWDfXdnAhp",
        "outputId": "184ce519-c121-4638-d9c6-85a357100f2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "metadata": {
        "id": "gFwYYGcJnvPj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_paper_text = data.map(preprocess)\n",
        "preprocessed_paper_text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ39lXuDn4mg",
        "outputId": "121a318e-b347-43e7-ea7f-2ece8e2daaa9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [self, organ, associ, databas, applic, hisashi...\n",
              "1    [mean, field, theori, layer, visual, cortex, a...\n",
              "2    [store, covari, associ, long, term, potenti, d...\n",
              "3    [bayesian, queri, construct, neural, network, ...\n",
              "4    [neural, network, ensembl, cross, valid, activ...\n",
              "Name: paper_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag pf words on dataset\n",
        "dictionary = gensim.corpora.Dictionary(preprocessed_paper_text)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9WCACrmoHfb",
        "outputId": "94bec59d-2f0e-4987-977b-1ffc4562fcff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 abolish\n",
            "1 abstract\n",
            "2 acceler\n",
            "3 accept\n",
            "4 accomplish\n",
            "5 accord\n",
            "6 achiev\n",
            "7 actual\n",
            "8 adap\n",
            "9 address\n",
            "10 adjac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2H8B_wiqQH6",
        "outputId": "38777cca-253e-49ba-d048-df1f0ad3b127"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (4, 1),\n",
              " (14, 1),\n",
              " (16, 3),\n",
              " (18, 1),\n",
              " (24, 2),\n",
              " (27, 1),\n",
              " (32, 2),\n",
              " (35, 1),\n",
              " (36, 1),\n",
              " (51, 1),\n",
              " (53, 1),\n",
              " (76, 1),\n",
              " (77, 3),\n",
              " (93, 2),\n",
              " (99, 1),\n",
              " (101, 2),\n",
              " (104, 1),\n",
              " (109, 1),\n",
              " (120, 1),\n",
              " (122, 3),\n",
              " (124, 4),\n",
              " (129, 1),\n",
              " (133, 3),\n",
              " (134, 2),\n",
              " (136, 6),\n",
              " (146, 5),\n",
              " (153, 1),\n",
              " (169, 2),\n",
              " (171, 1),\n",
              " (175, 1),\n",
              " (189, 1),\n",
              " (193, 1),\n",
              " (198, 1),\n",
              " (205, 18),\n",
              " (211, 1),\n",
              " (212, 1),\n",
              " (213, 2),\n",
              " (241, 2),\n",
              " (244, 2),\n",
              " (245, 7),\n",
              " (252, 1),\n",
              " (255, 1),\n",
              " (261, 1),\n",
              " (263, 4),\n",
              " (265, 1),\n",
              " (266, 7),\n",
              " (269, 1),\n",
              " (271, 1),\n",
              " (278, 7),\n",
              " (285, 1),\n",
              " (291, 2),\n",
              " (297, 2),\n",
              " (302, 4),\n",
              " (305, 4),\n",
              " (307, 1),\n",
              " (308, 1),\n",
              " (310, 4),\n",
              " (311, 1),\n",
              " (317, 37),\n",
              " (318, 2),\n",
              " (320, 5),\n",
              " (323, 18),\n",
              " (338, 5),\n",
              " (348, 1),\n",
              " (364, 1),\n",
              " (365, 1),\n",
              " (366, 1),\n",
              " (368, 2),\n",
              " (379, 1),\n",
              " (388, 1),\n",
              " (392, 1),\n",
              " (393, 3),\n",
              " (400, 6),\n",
              " (402, 4),\n",
              " (420, 1),\n",
              " (440, 4),\n",
              " (450, 1),\n",
              " (451, 3),\n",
              " (461, 1),\n",
              " (470, 1),\n",
              " (477, 1),\n",
              " (499, 2),\n",
              " (506, 1),\n",
              " (514, 1),\n",
              " (515, 1),\n",
              " (518, 3),\n",
              " (523, 1),\n",
              " (525, 2),\n",
              " (528, 1),\n",
              " (531, 1),\n",
              " (532, 4),\n",
              " (535, 1),\n",
              " (541, 3),\n",
              " (545, 2),\n",
              " (548, 2),\n",
              " (554, 1),\n",
              " (557, 40),\n",
              " (564, 1),\n",
              " (569, 3),\n",
              " (576, 1),\n",
              " (614, 2),\n",
              " (617, 6),\n",
              " (633, 2),\n",
              " (648, 2),\n",
              " (650, 1),\n",
              " (657, 3),\n",
              " (680, 3),\n",
              " (691, 5),\n",
              " (730, 4),\n",
              " (734, 2),\n",
              " (750, 1),\n",
              " (754, 1),\n",
              " (756, 1),\n",
              " (758, 1),\n",
              " (768, 1),\n",
              " (782, 2),\n",
              " (784, 7),\n",
              " (794, 1),\n",
              " (795, 1),\n",
              " (819, 21),\n",
              " (836, 7),\n",
              " (849, 2),\n",
              " (854, 3),\n",
              " (856, 1),\n",
              " (862, 1),\n",
              " (870, 27),\n",
              " (871, 1),\n",
              " (873, 1),\n",
              " (876, 5),\n",
              " (880, 4),\n",
              " (882, 1),\n",
              " (886, 1),\n",
              " (891, 2),\n",
              " (897, 4),\n",
              " (903, 1),\n",
              " (906, 2),\n",
              " (909, 1),\n",
              " (911, 2),\n",
              " (912, 1),\n",
              " (913, 1),\n",
              " (916, 2),\n",
              " (918, 1),\n",
              " (929, 1),\n",
              " (930, 10),\n",
              " (934, 1),\n",
              " (935, 3),\n",
              " (939, 1),\n",
              " (949, 1),\n",
              " (950, 1),\n",
              " (951, 2),\n",
              " (953, 1),\n",
              " (957, 7),\n",
              " (965, 1),\n",
              " (969, 1),\n",
              " (978, 1),\n",
              " (981, 1),\n",
              " (983, 4),\n",
              " (986, 1),\n",
              " (994, 2),\n",
              " (1001, 1),\n",
              " (1002, 2),\n",
              " (1006, 1),\n",
              " (1007, 3),\n",
              " (1012, 12),\n",
              " (1014, 2),\n",
              " (1016, 2),\n",
              " (1018, 13),\n",
              " (1019, 1),\n",
              " (1024, 1),\n",
              " (1026, 2),\n",
              " (1032, 1),\n",
              " (1033, 9),\n",
              " (1036, 1),\n",
              " (1041, 1),\n",
              " (1045, 1),\n",
              " (1046, 1),\n",
              " (1101, 18),\n",
              " (1118, 2),\n",
              " (1135, 2),\n",
              " (1146, 3),\n",
              " (1147, 2),\n",
              " (1155, 1),\n",
              " (1156, 1),\n",
              " (1164, 1),\n",
              " (1173, 1),\n",
              " (1183, 1),\n",
              " (1186, 2),\n",
              " (1198, 2),\n",
              " (1211, 1),\n",
              " (1215, 1),\n",
              " (1217, 4),\n",
              " (1219, 2),\n",
              " (1229, 1),\n",
              " (1233, 2),\n",
              " (1259, 1),\n",
              " (1265, 1),\n",
              " (1267, 1),\n",
              " (1274, 1),\n",
              " (1289, 31),\n",
              " (1302, 3),\n",
              " (1313, 8),\n",
              " (1324, 5),\n",
              " (1354, 2),\n",
              " (1375, 1),\n",
              " (1386, 2),\n",
              " (1401, 1),\n",
              " (1418, 3),\n",
              " (1429, 2),\n",
              " (1437, 4),\n",
              " (1441, 1),\n",
              " (1442, 1),\n",
              " (1446, 1),\n",
              " (1448, 2),\n",
              " (1468, 1),\n",
              " (1469, 1),\n",
              " (1497, 1),\n",
              " (1510, 2),\n",
              " (1548, 1),\n",
              " (1550, 1),\n",
              " (1554, 1),\n",
              " (1561, 2),\n",
              " (1584, 1),\n",
              " (1605, 1),\n",
              " (1622, 1),\n",
              " (1626, 1),\n",
              " (1634, 1),\n",
              " (1649, 3),\n",
              " (1653, 6),\n",
              " (1664, 7),\n",
              " (1667, 1),\n",
              " (1689, 1),\n",
              " (1696, 3),\n",
              " (1724, 1),\n",
              " (1749, 1),\n",
              " (1752, 1),\n",
              " (1771, 2),\n",
              " (1776, 1),\n",
              " (1787, 1),\n",
              " (1798, 1),\n",
              " (1807, 2),\n",
              " (1810, 24),\n",
              " (1812, 2),\n",
              " (1830, 1),\n",
              " (1852, 1),\n",
              " (1859, 1),\n",
              " (1866, 1),\n",
              " (1868, 1),\n",
              " (1933, 1),\n",
              " (1995, 2),\n",
              " (2006, 2),\n",
              " (2026, 1),\n",
              " (2053, 1),\n",
              " (2054, 1),\n",
              " (2075, 1),\n",
              " (2097, 2),\n",
              " (2098, 1),\n",
              " (2105, 1),\n",
              " (2156, 2),\n",
              " (2183, 1),\n",
              " (2221, 2),\n",
              " (2229, 1),\n",
              " (2237, 2),\n",
              " (2258, 3),\n",
              " (2295, 1),\n",
              " (2311, 1),\n",
              " (2378, 1),\n",
              " (2384, 1),\n",
              " (2386, 1),\n",
              " (2404, 2),\n",
              " (2405, 1),\n",
              " (2413, 5),\n",
              " (2458, 2),\n",
              " (2481, 5),\n",
              " (2499, 3),\n",
              " (2558, 1),\n",
              " (2566, 1),\n",
              " (2597, 1),\n",
              " (2634, 1),\n",
              " (2649, 1),\n",
              " (2650, 5),\n",
              " (2666, 1),\n",
              " (2674, 1),\n",
              " (2676, 5),\n",
              " (2702, 2),\n",
              " (2718, 1),\n",
              " (2757, 2),\n",
              " (2780, 1),\n",
              " (2786, 2),\n",
              " (2797, 2),\n",
              " (2801, 1),\n",
              " (2815, 21),\n",
              " (2819, 1),\n",
              " (2831, 4),\n",
              " (2833, 2),\n",
              " (2848, 1),\n",
              " (2861, 2),\n",
              " (2946, 2),\n",
              " (2997, 3),\n",
              " (3025, 1),\n",
              " (3028, 3),\n",
              " (3037, 1),\n",
              " (3054, 1),\n",
              " (3057, 1),\n",
              " (3106, 1),\n",
              " (3112, 6),\n",
              " (3117, 1),\n",
              " (3118, 1),\n",
              " (3150, 1),\n",
              " (3165, 1),\n",
              " (3303, 1),\n",
              " (3355, 2),\n",
              " (3431, 1),\n",
              " (3443, 1),\n",
              " (3459, 1),\n",
              " (3469, 1),\n",
              " (3517, 1),\n",
              " (3533, 1),\n",
              " (3536, 1),\n",
              " (3579, 1),\n",
              " (3585, 9),\n",
              " (3627, 1),\n",
              " (3645, 1),\n",
              " (3664, 8),\n",
              " (3831, 1),\n",
              " (3835, 2),\n",
              " (3840, 1),\n",
              " (3911, 1),\n",
              " (3956, 1),\n",
              " (4061, 1),\n",
              " (4135, 1),\n",
              " (4289, 1),\n",
              " (4362, 1),\n",
              " (4417, 1),\n",
              " (4431, 1),\n",
              " (4483, 1),\n",
              " (4592, 9),\n",
              " (4657, 1),\n",
              " (4695, 1),\n",
              " (4804, 2),\n",
              " (5059, 1),\n",
              " (5257, 1),\n",
              " (5260, 1),\n",
              " (5265, 1),\n",
              " (5266, 1),\n",
              " (5271, 1),\n",
              " (5626, 3),\n",
              " (6112, 1),\n",
              " (6115, 1),\n",
              " (6231, 1),\n",
              " (6287, 1),\n",
              " (6340, 1),\n",
              " (6397, 1),\n",
              " (6419, 1),\n",
              " (6503, 3),\n",
              " (6510, 2),\n",
              " (6526, 1),\n",
              " (6598, 1),\n",
              " (6800, 5),\n",
              " (6889, 3),\n",
              " (7068, 1),\n",
              " (7120, 1),\n",
              " (7414, 1),\n",
              " (7423, 1),\n",
              " (7545, 3),\n",
              " (7554, 1),\n",
              " (7752, 1),\n",
              " (7792, 1),\n",
              " (7797, 2),\n",
              " (8055, 1),\n",
              " (8201, 1),\n",
              " (8417, 8),\n",
              " (8601, 1),\n",
              " (8660, 2),\n",
              " (8859, 1),\n",
              " (8888, 1),\n",
              " (8969, 2),\n",
              " (8970, 1),\n",
              " (9038, 1),\n",
              " (9174, 1),\n",
              " (9248, 1),\n",
              " (9249, 1),\n",
              " (9456, 1),\n",
              " (9618, 1),\n",
              " (9703, 2),\n",
              " (9753, 2),\n",
              " (9967, 1),\n",
              " (10000, 1),\n",
              " (10012, 1),\n",
              " (10301, 1),\n",
              " (10335, 1),\n",
              " (10351, 1),\n",
              " (10430, 1),\n",
              " (10528, 1),\n",
              " (10581, 1),\n",
              " (10686, 1),\n",
              " (10928, 12)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow_doc_4310 = bow_corpus[4310]\n",
        "\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                                     dictionary[bow_doc_4310[i][0]], \n",
        "                                                     bow_doc_4310[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcX90_YlqcbZ",
        "outputId": "30deb288-0759-46dc-9822-0a57bb2a1f4c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 1 (\"acceler\") appears 1 time.\n",
            "Word 4 (\"actual\") appears 1 time.\n",
            "Word 14 (\"appropri\") appears 1 time.\n",
            "Word 16 (\"arbitrarili\") appears 3 time.\n",
            "Word 18 (\"area\") appears 1 time.\n",
            "Word 24 (\"aspect\") appears 2 time.\n",
            "Word 27 (\"attain\") appears 1 time.\n",
            "Word 32 (\"avoid\") appears 2 time.\n",
            "Word 35 (\"binari\") appears 1 time.\n",
            "Word 36 (\"black\") appears 1 time.\n",
            "Word 51 (\"chapter\") appears 1 time.\n",
            "Word 53 (\"check\") appears 1 time.\n",
            "Word 76 (\"correl\") appears 1 time.\n",
            "Word 77 (\"cost\") appears 3 time.\n",
            "Word 93 (\"desir\") appears 2 time.\n",
            "Word 99 (\"display\") appears 1 time.\n",
            "Word 101 (\"distanc\") appears 2 time.\n",
            "Word 104 (\"divid\") appears 1 time.\n",
            "Word 109 (\"easi\") appears 1 time.\n",
            "Word 120 (\"essenti\") appears 1 time.\n",
            "Word 122 (\"euclidean\") appears 3 time.\n",
            "Word 124 (\"excess\") appears 4 time.\n",
            "Word 129 (\"face\") appears 1 time.\n",
            "Word 133 (\"fast\") appears 3 time.\n",
            "Word 134 (\"faster\") appears 2 time.\n",
            "Word 136 (\"finit\") appears 6 time.\n",
            "Word 146 (\"global\") appears 5 time.\n",
            "Word 153 (\"hard\") appears 1 time.\n",
            "Word 169 (\"impli\") appears 2 time.\n",
            "Word 171 (\"impos\") appears 1 time.\n",
            "Word 175 (\"infinit\") appears 1 time.\n",
            "Word 189 (\"knowledg\") appears 1 time.\n",
            "Word 193 (\"lack\") appears 1 time.\n",
            "Word 198 (\"letter\") appears 1 time.\n",
            "Word 205 (\"loss\") appears 18 time.\n",
            "Word 211 (\"mark\") appears 1 time.\n",
            "Word 212 (\"match\") appears 1 time.\n",
            "Word 213 (\"mathemat\") appears 2 time.\n",
            "Word 241 (\"pair\") appears 2 time.\n",
            "Word 244 (\"partial\") appears 2 time.\n",
            "Word 245 (\"pass\") appears 7 time.\n",
            "Word 252 (\"play\") appears 1 time.\n",
            "Word 255 (\"precis\") appears 1 time.\n",
            "Word 261 (\"produc\") appears 1 time.\n",
            "Word 263 (\"project\") appears 4 time.\n",
            "Word 265 (\"proper\") appears 1 time.\n",
            "Word 266 (\"proport\") appears 7 time.\n",
            "Word 269 (\"quick\") appears 1 time.\n",
            "Word 271 (\"ratio\") appears 1 time.\n",
            "Word 278 (\"recurs\") appears 7 time.\n",
            "Word 285 (\"respons\") appears 1 time.\n",
            "Word 291 (\"role\") appears 2 time.\n",
            "Word 297 (\"run\") appears 2 time.\n",
            "Word 302 (\"self\") appears 4 time.\n",
            "Word 305 (\"sequenc\") appears 4 time.\n",
            "Word 307 (\"simplest\") appears 1 time.\n",
            "Word 308 (\"situat\") appears 1 time.\n",
            "Word 310 (\"slight\") appears 4 time.\n",
            "Word 311 (\"slowli\") appears 1 time.\n",
            "Word 317 (\"squar\") appears 37 time.\n",
            "Word 318 (\"stage\") appears 2 time.\n",
            "Word 320 (\"stationari\") appears 5 time.\n",
            "Word 323 (\"strong\") appears 18 time.\n",
            "Word 338 (\"sure\") appears 5 time.\n",
            "Word 348 (\"temporarili\") appears 1 time.\n",
            "Word 364 (\"understand\") appears 1 time.\n",
            "Word 365 (\"uniqu\") appears 1 time.\n",
            "Word 366 (\"unit\") appears 1 time.\n",
            "Word 368 (\"upper\") appears 2 time.\n",
            "Word 379 (\"wide\") appears 1 time.\n",
            "Word 388 (\"advantag\") appears 1 time.\n",
            "Word 392 (\"amount\") appears 1 time.\n",
            "Word 393 (\"analyz\") appears 3 time.\n",
            "Word 400 (\"asymptot\") appears 6 time.\n",
            "Word 402 (\"behavior\") appears 4 time.\n",
            "Word 420 (\"constraint\") appears 1 time.\n",
            "Word 440 (\"earli\") appears 4 time.\n",
            "Word 450 (\"explicit\") appears 1 time.\n",
            "Word 451 (\"extens\") appears 3 time.\n",
            "Word 461 (\"help\") appears 1 time.\n",
            "Word 470 (\"interpret\") appears 1 time.\n",
            "Word 477 (\"later\") appears 1 time.\n",
            "Word 499 (\"nois\") appears 2 time.\n",
            "Word 506 (\"outsid\") appears 1 time.\n",
            "Word 514 (\"potenti\") appears 1 time.\n",
            "Word 515 (\"prefer\") appears 1 time.\n",
            "Word 518 (\"proc\") appears 3 time.\n",
            "Word 523 (\"quantiti\") appears 1 time.\n",
            "Word 525 (\"reach\") appears 2 time.\n",
            "Word 528 (\"recurr\") appears 1 time.\n",
            "Word 531 (\"relax\") appears 1 time.\n",
            "Word 532 (\"replac\") appears 4 time.\n",
            "Word 535 (\"restrict\") appears 1 time.\n",
            "Word 541 (\"satisfi\") appears 3 time.\n",
            "Word 545 (\"signal\") appears 2 time.\n",
            "Word 548 (\"singer\") appears 2 time.\n",
            "Word 554 (\"stabil\") appears 1 time.\n",
            "Word 557 (\"stochast\") appears 40 time.\n",
            "Word 564 (\"thank\") appears 1 time.\n",
            "Word 569 (\"tune\") appears 3 time.\n",
            "Word 576 (\"vari\") appears 1 time.\n",
            "Word 614 (\"context\") appears 2 time.\n",
            "Word 617 (\"covari\") appears 6 time.\n",
            "Word 633 (\"exhibit\") appears 2 time.\n",
            "Word 648 (\"harri\") appears 2 time.\n",
            "Word 650 (\"higher\") appears 1 time.\n",
            "Word 657 (\"ident\") appears 3 time.\n",
            "Word 680 (\"middl\") appears 3 time.\n",
            "Word 691 (\"novel\") appears 5 time.\n",
            "Word 730 (\"smaller\") appears 4 time.\n",
            "Word 734 (\"springer\") appears 2 time.\n",
            "Word 750 (\"transmiss\") appears 1 time.\n",
            "Word 754 (\"univ\") appears 1 time.\n",
            "Word 756 (\"verlag\") appears 1 time.\n",
            "Word 758 (\"weak\") appears 1 time.\n",
            "Word 768 (\"affect\") appears 1 time.\n",
            "Word 782 (\"cambridg\") appears 2 time.\n",
            "Word 784 (\"chain\") appears 7 time.\n",
            "Word 794 (\"determinist\") appears 1 time.\n",
            "Word 795 (\"deviat\") appears 1 time.\n",
            "Word 819 (\"gradient\") appears 21 time.\n",
            "Word 836 (\"markov\") appears 7 time.\n",
            "Word 849 (\"nip\") appears 2 time.\n",
            "Word 854 (\"optimum\") appears 3 time.\n",
            "Word 856 (\"part\") appears 1 time.\n",
            "Word 862 (\"probabilist\") appears 1 time.\n",
            "Word 870 (\"regress\") appears 27 time.\n",
            "Word 871 (\"regular\") appears 1 time.\n",
            "Word 873 (\"reli\") appears 1 time.\n",
            "Word 876 (\"risk\") appears 5 time.\n",
            "Word 880 (\"see\") appears 4 time.\n",
            "Word 882 (\"sequenti\") appears 1 time.\n",
            "Word 886 (\"smallest\") appears 1 time.\n",
            "Word 891 (\"strategi\") appears 2 time.\n",
            "Word 897 (\"technic\") appears 4 time.\n",
            "Word 903 (\"trivial\") appears 1 time.\n",
            "Word 906 (\"uniform\") appears 2 time.\n",
            "Word 909 (\"valid\") appears 1 time.\n",
            "Word 911 (\"variant\") appears 2 time.\n",
            "Word 912 (\"variat\") appears 1 time.\n",
            "Word 913 (\"volum\") appears 1 time.\n",
            "Word 916 (\"wiley\") appears 2 time.\n",
            "Word 918 (\"abl\") appears 1 time.\n",
            "Word 929 (\"bias\") appears 1 time.\n",
            "Word 930 (\"bind\") appears 10 time.\n",
            "Word 934 (\"central\") appears 1 time.\n",
            "Word 935 (\"certain\") appears 3 time.\n",
            "Word 939 (\"classif\") appears 1 time.\n",
            "Word 949 (\"crucial\") appears 1 time.\n",
            "Word 950 (\"curv\") appears 1 time.\n",
            "Word 951 (\"dash\") appears 2 time.\n",
            "Word 953 (\"deal\") appears 1 time.\n",
            "Word 957 (\"descent\") appears 7 time.\n",
            "Word 965 (\"electron\") appears 1 time.\n",
            "Word 969 (\"ensur\") appears 1 time.\n",
            "Word 978 (\"get\") appears 1 time.\n",
            "Word 981 (\"happen\") appears 1 time.\n",
            "Word 983 (\"hold\") appears 4 time.\n",
            "Word 986 (\"instanc\") appears 1 time.\n",
            "Word 994 (\"lowest\") appears 2 time.\n",
            "Word 1001 (\"minimum\") appears 1 time.\n",
            "Word 1002 (\"mixtur\") appears 2 time.\n",
            "Word 1006 (\"overal\") appears 1 time.\n",
            "Word 1007 (\"overfit\") appears 3 time.\n",
            "Word 1012 (\"plot\") appears 12 time.\n",
            "Word 1014 (\"predictor\") appears 2 time.\n",
            "Word 1016 (\"program\") appears 2 time.\n",
            "Word 1018 (\"quadrat\") appears 13 time.\n",
            "Word 1019 (\"quantifi\") appears 1 time.\n",
            "Word 1024 (\"say\") appears 1 time.\n",
            "Word 1026 (\"scheme\") appears 2 time.\n",
            "Word 1032 (\"simpli\") appears 1 time.\n",
            "Word 1033 (\"smooth\") appears 9 time.\n",
            "Word 1036 (\"speech\") appears 1 time.\n",
            "Word 1041 (\"text\") appears 1 time.\n",
            "Word 1045 (\"tradeoff\") appears 1 time.\n",
            "Word 1046 (\"transact\") appears 1 time.\n",
            "Word 1101 (\"dataset\") appears 18 time.\n",
            "Word 1118 (\"explain\") appears 2 time.\n",
            "Word 1135 (\"hessian\") appears 2 time.\n",
            "Word 1146 (\"invari\") appears 3 time.\n",
            "Word 1147 (\"invert\") appears 2 time.\n",
            "Word 1155 (\"logarithm\") appears 1 time.\n",
            "Word 1156 (\"longer\") appears 1 time.\n",
            "Word 1164 (\"notabl\") appears 1 time.\n",
            "Word 1173 (\"perturb\") appears 1 time.\n",
            "Word 1183 (\"qualiti\") appears 1 time.\n",
            "Word 1186 (\"relationship\") appears 2 time.\n",
            "Word 1198 (\"sharp\") appears 2 time.\n",
            "Word 1211 (\"spline\") appears 1 time.\n",
            "Word 1215 (\"sum\") appears 1 time.\n",
            "Word 1217 (\"tabl\") appears 4 time.\n",
            "Word 1219 (\"tend\") appears 2 time.\n",
            "Word 1229 (\"underli\") appears 1 time.\n",
            "Word 1233 (\"way\") appears 2 time.\n",
            "Word 1259 (\"differenti\") appears 1 time.\n",
            "Word 1265 (\"engin\") appears 1 time.\n",
            "Word 1267 (\"exponenti\") appears 1 time.\n",
            "Word 1274 (\"frequent\") appears 1 time.\n",
            "Word 1289 (\"logist\") appears 31 time.\n",
            "Word 1302 (\"preserv\") appears 3 time.\n",
            "Word 1313 (\"spars\") appears 8 time.\n",
            "Word 1324 (\"updat\") appears 5 time.\n",
            "Word 1354 (\"column\") appears 2 time.\n",
            "Word 1375 (\"extra\") appears 1 time.\n",
            "Word 1386 (\"greater\") appears 2 time.\n",
            "Word 1401 (\"kluwer\") appears 1 time.\n",
            "Word 1418 (\"onlin\") appears 3 time.\n",
            "Word 1429 (\"power\") appears 2 time.\n",
            "Word 1437 (\"robust\") appears 4 time.\n",
            "Word 1441 (\"sign\") appears 1 time.\n",
            "Word 1442 (\"slowest\") appears 1 time.\n",
            "Word 1446 (\"strict\") appears 1 time.\n",
            "Word 1448 (\"success\") appears 2 time.\n",
            "Word 1468 (\"year\") appears 1 time.\n",
            "Word 1469 (\"accur\") appears 1 time.\n",
            "Word 1497 (\"earlier\") appears 1 time.\n",
            "Word 1510 (\"go\") appears 2 time.\n",
            "Word 1548 (\"radius\") appears 1 time.\n",
            "Word 1550 (\"residu\") appears 1 time.\n",
            "Word 1554 (\"sensit\") appears 1 time.\n",
            "Word 1561 (\"tail\") appears 2 time.\n",
            "Word 1584 (\"council\") appears 1 time.\n",
            "Word 1605 (\"issu\") appears 1 time.\n",
            "Word 1622 (\"remov\") appears 1 time.\n",
            "Word 1626 (\"scope\") appears 1 time.\n",
            "Word 1634 (\"ubiquit\") appears 1 time.\n",
            "Word 1649 (\"benchmark\") appears 3 time.\n",
            "Word 1653 (\"bound\") appears 6 time.\n",
            "Word 1664 (\"decay\") appears 7 time.\n",
            "Word 1667 (\"definit\") appears 1 time.\n",
            "Word 1689 (\"goal\") appears 1 time.\n",
            "Word 1696 (\"harder\") appears 3 time.\n",
            "Word 1724 (\"loos\") appears 1 time.\n",
            "Word 1749 (\"rank\") appears 1 time.\n",
            "Word 1752 (\"reinforc\") appears 1 time.\n",
            "Word 1771 (\"specifi\") appears 2 time.\n",
            "Word 1776 (\"surpris\") appears 1 time.\n",
            "Word 1787 (\"track\") appears 1 time.\n",
            "Word 1798 (\"wors\") appears 1 time.\n",
            "Word 1807 (\"classic\") appears 2 time.\n",
            "Word 1810 (\"convex\") appears 24 time.\n",
            "Word 1812 (\"diagon\") appears 2 time.\n",
            "Word 1830 (\"inequ\") appears 1 time.\n",
            "Word 1852 (\"parametr\") appears 1 time.\n",
            "Word 1859 (\"proxim\") appears 1 time.\n",
            "Word 1866 (\"stationar\") appears 1 time.\n",
            "Word 1868 (\"subspac\") appears 1 time.\n",
            "Word 1933 (\"ax\") appears 1 time.\n",
            "Word 1995 (\"degre\") appears 2 time.\n",
            "Word 2006 (\"forget\") appears 2 time.\n",
            "Word 2026 (\"matric\") appears 1 time.\n",
            "Word 2053 (\"schmidt\") appears 1 time.\n",
            "Word 2054 (\"semi\") appears 1 time.\n",
            "Word 2075 (\"walk\") appears 1 time.\n",
            "Word 2097 (\"outperform\") appears 2 time.\n",
            "Word 2098 (\"practition\") appears 1 time.\n",
            "Word 2105 (\"supervis\") appears 1 time.\n",
            "Word 2156 (\"trick\") appears 2 time.\n",
            "Word 2183 (\"expans\") appears 1 time.\n",
            "Word 2221 (\"replic\") appears 2 time.\n",
            "Word 2229 (\"share\") appears 1 time.\n",
            "Word 2237 (\"stronger\") appears 2 time.\n",
            "Word 2258 (\"color\") appears 3 time.\n",
            "Word 2295 (\"acoust\") appears 1 time.\n",
            "Word 2311 (\"edit\") appears 1 time.\n",
            "Word 2378 (\"composit\") appears 1 time.\n",
            "Word 2384 (\"entri\") appears 1 time.\n",
            "Word 2386 (\"ergod\") appears 1 time.\n",
            "Word 2404 (\"norm\") appears 2 time.\n",
            "Word 2405 (\"novelti\") appears 1 time.\n",
            "Word 2413 (\"rat\") appears 5 time.\n",
            "Word 2458 (\"homogen\") appears 2 time.\n",
            "Word 2481 (\"proof\") appears 5 time.\n",
            "Word 2499 (\"twice\") appears 3 time.\n",
            "Word 2558 (\"polynomi\") appears 1 time.\n",
            "Word 2566 (\"scenario\") appears 1 time.\n",
            "Word 2597 (\"increment\") appears 1 time.\n",
            "Word 2634 (\"tradit\") appears 1 time.\n",
            "Word 2649 (\"difficulti\") appears 1 time.\n",
            "Word 2650 (\"eigenvalu\") appears 5 time.\n",
            "Word 2666 (\"oscil\") appears 1 time.\n",
            "Word 2674 (\"son\") appears 1 time.\n",
            "Word 2676 (\"synthet\") appears 5 time.\n",
            "Word 2702 (\"doubl\") appears 2 time.\n",
            "Word 2718 (\"mention\") appears 1 time.\n",
            "Word 2757 (\"freedom\") appears 2 time.\n",
            "Word 2780 (\"barrier\") appears 1 time.\n",
            "Word 2786 (\"coincid\") appears 2 time.\n",
            "Word 2797 (\"eric\") appears 2 time.\n",
            "Word 2801 (\"finer\") appears 1 time.\n",
            "Word 2815 (\"newton\") appears 21 time.\n",
            "Word 2819 (\"oppos\") appears 1 time.\n",
            "Word 2831 (\"siam\") appears 4 time.\n",
            "Word 2833 (\"sparsiti\") appears 2 time.\n",
            "Word 2848 (\"behav\") appears 1 time.\n",
            "Word 2861 (\"inferior\") appears 2 time.\n",
            "Word 2946 (\"pari\") appears 2 time.\n",
            "Word 2997 (\"stepsiz\") appears 3 time.\n",
            "Word 3025 (\"lie\") appears 1 time.\n",
            "Word 3028 (\"moment\") appears 3 time.\n",
            "Word 3037 (\"quicker\") appears 1 time.\n",
            "Word 3054 (\"decent\") appears 1 time.\n",
            "Word 3057 (\"european\") appears 1 time.\n",
            "Word 3106 (\"notion\") appears 1 time.\n",
            "Word 3112 (\"theorem\") appears 6 time.\n",
            "Word 3117 (\"annal\") appears 1 time.\n",
            "Word 3118 (\"approx\") appears 1 time.\n",
            "Word 3150 (\"underfit\") appears 1 time.\n",
            "Word 3165 (\"dedic\") appears 1 time.\n",
            "Word 3303 (\"slower\") appears 1 time.\n",
            "Word 3355 (\"plain\") appears 2 time.\n",
            "Word 3431 (\"unregular\") appears 1 time.\n",
            "Word 3443 (\"introductori\") appears 1 time.\n",
            "Word 3459 (\"bertseka\") appears 1 time.\n",
            "Word 3469 (\"polyak\") appears 1 time.\n",
            "Word 3517 (\"telecom\") appears 1 time.\n",
            "Word 3533 (\"kurtosi\") appears 1 time.\n",
            "Word 3536 (\"outlier\") appears 1 time.\n",
            "Word 3579 (\"rescal\") appears 1 time.\n",
            "Word 3585 (\"alpha\") appears 9 time.\n",
            "Word 3627 (\"unbias\") appears 1 time.\n",
            "Word 3645 (\"inspir\") appears 1 time.\n",
            "Word 3664 (\"bach\") appears 8 time.\n",
            "Word 3831 (\"ecol\") appears 1 time.\n",
            "Word 3835 (\"franc\") appears 2 time.\n",
            "Word 3840 (\"inria\") appears 1 time.\n",
            "Word 3911 (\"protocol\") appears 1 time.\n",
            "Word 3956 (\"remedi\") appears 1 time.\n",
            "Word 4061 (\"bottou\") appears 1 time.\n",
            "Word 4135 (\"solver\") appears 1 time.\n",
            "Word 4289 (\"lighter\") appears 1 time.\n",
            "Word 4362 (\"vacuous\") appears 1 time.\n",
            "Word 4417 (\"team\") appears 1 time.\n",
            "Word 4431 (\"lectur\") appears 1 time.\n",
            "Word 4483 (\"west\") appears 1 time.\n",
            "Word 4592 (\"news\") appears 9 time.\n",
            "Word 4657 (\"corollari\") appears 1 time.\n",
            "Word 4695 (\"surrog\") appears 1 time.\n",
            "Word 4804 (\"colt\") appears 2 time.\n",
            "Word 5059 (\"eigenvector\") appears 1 time.\n",
            "Word 5257 (\"kushner\") appears 1 time.\n",
            "Word 5260 (\"monro\") appears 1 time.\n",
            "Word 5265 (\"regret\") appears 1 time.\n",
            "Word 5266 (\"robbin\") appears 1 time.\n",
            "Word 5271 (\"aggreg\") appears 1 time.\n",
            "Word 5626 (\"limn\") appears 3 time.\n",
            "Word 6112 (\"meyn\") appears 1 time.\n",
            "Word 6115 (\"tweedi\") appears 1 time.\n",
            "Word 6231 (\"worsen\") appears 1 time.\n",
            "Word 6287 (\"borkar\") appears 1 time.\n",
            "Word 6340 (\"primal\") appears 1 time.\n",
            "Word 6397 (\"cramer\") appears 1 time.\n",
            "Word 6419 (\"errat\") appears 1 time.\n",
            "Word 6503 (\"franci\") appears 3 time.\n",
            "Word 6510 (\"quantum\") appears 2 time.\n",
            "Word 6526 (\"shapiro\") appears 1 time.\n",
            "Word 6598 (\"anova\") appears 1 time.\n",
            "Word 6800 (\"moulin\") appears 5 time.\n",
            "Word 6889 (\"pointwis\") appears 3 time.\n",
            "Word 7068 (\"icml\") appears 1 time.\n",
            "Word 7120 (\"adjoint\") appears 1 time.\n",
            "Word 7414 (\"sussex\") appears 1 time.\n",
            "Word 7423 (\"kale\") appears 1 time.\n",
            "Word 7545 (\"concord\") appears 3 time.\n",
            "Word 7554 (\"nicola\") appears 1 time.\n",
            "Word 7752 (\"dyadic\") appears 1 time.\n",
            "Word 7792 (\"homoscedast\") appears 1 time.\n",
            "Word 7797 (\"juditski\") appears 2 time.\n",
            "Word 8055 (\"fastica\") appears 1 time.\n",
            "Word 8201 (\"vaart\") appears 1 time.\n",
            "Word 8417 (\"covertyp\") appears 8 time.\n",
            "Word 8601 (\"bousquet\") appears 1 time.\n",
            "Word 8660 (\"subgradi\") appears 2 time.\n",
            "Word 8859 (\"shwartz\") appears 1 time.\n",
            "Word 8888 (\"arinen\") appears 1 time.\n",
            "Word 8969 (\"nemirovski\") appears 2 time.\n",
            "Word 8970 (\"nesterov\") appears 1 time.\n",
            "Word 9038 (\"srebro\") appears 1 time.\n",
            "Word 9174 (\"nonasymptot\") appears 1 time.\n",
            "Word 9248 (\"orfi\") appears 1 time.\n",
            "Word 9249 (\"tsybakov\") appears 1 time.\n",
            "Word 9456 (\"shalev\") appears 1 time.\n",
            "Word 9618 (\"roux\") appears 1 time.\n",
            "Word 9703 (\"sierra\") appears 2 time.\n",
            "Word 9753 (\"hazan\") appears 2 time.\n",
            "Word 9967 (\"paristech\") appears 1 time.\n",
            "Word 10000 (\"yudin\") appears 1 time.\n",
            "Word 10012 (\"supn\") appears 1 time.\n",
            "Word 10301 (\"duchi\") appears 1 time.\n",
            "Word 10335 (\"ltci\") appears 1 time.\n",
            "Word 10351 (\"pegaso\") appears 1 time.\n",
            "Word 10430 (\"erieur\") appears 1 time.\n",
            "Word 10528 (\"pathwis\") appears 1 time.\n",
            "Word 10581 (\"nedic\") appears 1 time.\n",
            "Word 10686 (\"unimprov\") appears 1 time.\n",
            "Word 10928 (\"adagrad\") appears 12 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf\n",
        "from gensim import corpora, models\n",
        "from pprint import pprint\n",
        "\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIgUsaGvqn8v",
        "outputId": "2226821f-54e1-4eb4-dccb-79c3b7685fdc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.04645512099680736),\n",
            " (1, 0.016194928210910717),\n",
            " (2, 0.03096844659650005),\n",
            " (3, 0.018426259160709415),\n",
            " (4, 0.020461159529786836),\n",
            " (5, 0.01376512754213418),\n",
            " (6, 0.01659453474408978),\n",
            " (7, 0.012641218904195561),\n",
            " (8, 0.01335711487765653),\n",
            " (9, 0.02461038396068751),\n",
            " (10, 0.010087372820476804),\n",
            " (11, 0.016343478223700688),\n",
            " (12, 0.02661966195179876),\n",
            " (13, 0.02849254213874603),\n",
            " (14, 0.0068436445356545505),\n",
            " (15, 0.007354451089734281),\n",
            " (16, 0.014485476057756104),\n",
            " (17, 0.01936239523311201),\n",
            " (18, 0.06139049065156623),\n",
            " (19, 0.0468978820085069),\n",
            " (20, 0.01002468186537162),\n",
            " (21, 0.018577807583822378),\n",
            " (22, 0.016540047704476257),\n",
            " (23, 0.014027450397921304),\n",
            " (24, 0.01076531620187347),\n",
            " (25, 0.007584525635881085),\n",
            " (26, 0.027764036850892904),\n",
            " (27, 0.04983834778309642),\n",
            " (28, 0.016662733045685118),\n",
            " (29, 0.07570783072618265),\n",
            " (30, 0.009854852845925325),\n",
            " (31, 0.1138491149216239),\n",
            " (32, 0.03202349391535267),\n",
            " (33, 0.013782600583098046),\n",
            " (34, 0.011641809939569392),\n",
            " (35, 0.021449513391755593),\n",
            " (36, 0.11461301941929262),\n",
            " (37, 0.07748412318484771),\n",
            " (38, 0.023445670146311853),\n",
            " (39, 0.02081410521667381),\n",
            " (40, 0.0322940665541428),\n",
            " (41, 0.020906642051772985),\n",
            " (42, 0.007310344443253011),\n",
            " (43, 0.023185268857904066),\n",
            " (44, 0.253641068817111),\n",
            " (45, 0.05608306475253168),\n",
            " (46, 0.01684458351877672),\n",
            " (47, 0.029777119991505098),\n",
            " (48, 0.030135094326590256),\n",
            " (49, 0.01359472858873692),\n",
            " (50, 0.007160615133056182),\n",
            " (51, 0.02089306827413847),\n",
            " (52, 0.05911056447471657),\n",
            " (53, 0.015009504669843875),\n",
            " (54, 0.02727857336688393),\n",
            " (55, 0.017647144650975943),\n",
            " (56, 0.026074154834935394),\n",
            " (57, 0.008448280725832789),\n",
            " (58, 0.03125970449753233),\n",
            " (59, 0.03335398146458598),\n",
            " (60, 0.02073554587609526),\n",
            " (61, 0.007147145804571493),\n",
            " (62, 0.06301127309140815),\n",
            " (63, 0.017322629791490688),\n",
            " (64, 0.0685973447355112),\n",
            " (65, 0.029138439343730428),\n",
            " (66, 0.0645383161323092),\n",
            " (67, 0.047367492991143824),\n",
            " (68, 0.022997773804926187),\n",
            " (69, 0.05303558111713225),\n",
            " (70, 0.0141926174601692),\n",
            " (71, 0.008941208373744552),\n",
            " (72, 0.019325109011215983),\n",
            " (73, 0.02448318555483227),\n",
            " (74, 0.14360226556613562),\n",
            " (75, 0.02175644758619009),\n",
            " (76, 0.007673316578339303),\n",
            " (77, 0.025604109236388985),\n",
            " (78, 0.048372339834171045),\n",
            " (79, 0.013650613303864408),\n",
            " (80, 0.011970858454632175),\n",
            " (81, 0.023871638002025398),\n",
            " (82, 0.035762551430457236),\n",
            " (83, 0.008486580971275227),\n",
            " (84, 0.03808983391918081),\n",
            " (85, 0.03132045938826996),\n",
            " (86, 0.24091253821468003),\n",
            " (87, 0.013161597888555494),\n",
            " (88, 0.013038509462761983),\n",
            " (89, 0.07617966783836162),\n",
            " (90, 0.034340239825061965),\n",
            " (91, 0.038227845447256874),\n",
            " (92, 0.04808365289004104),\n",
            " (93, 0.014686801722483014),\n",
            " (94, 0.009263364088507559),\n",
            " (95, 0.0067561449005604695),\n",
            " (96, 0.01758854096706055),\n",
            " (97, 0.03317193422033821),\n",
            " (98, 0.007112234767778987),\n",
            " (99, 0.014423257178191264),\n",
            " (100, 0.024089642700926128),\n",
            " (101, 0.013334184827505592),\n",
            " (102, 0.024584776635351403),\n",
            " (103, 0.012897039430416403),\n",
            " (104, 0.010620682070764147),\n",
            " (105, 0.04467473170077752),\n",
            " (106, 0.030962878571377368),\n",
            " (107, 0.03138169455980633),\n",
            " (108, 0.013283671519893677),\n",
            " (109, 0.008664588172303582),\n",
            " (110, 0.0066544537931324255),\n",
            " (111, 0.04213934686246568),\n",
            " (112, 0.05803228904086086),\n",
            " (113, 0.017595382900447064),\n",
            " (114, 0.02421049084400299),\n",
            " (115, 0.009217517965525321),\n",
            " (116, 0.047367492991143824),\n",
            " (117, 0.06987812278894057),\n",
            " (118, 0.025941789132952836),\n",
            " (119, 0.010384106542116968),\n",
            " (120, 0.00829694582493821),\n",
            " (121, 0.05938177387998372),\n",
            " (122, 0.02827866584856945),\n",
            " (123, 0.01892695768154566),\n",
            " (124, 0.06572793160704027),\n",
            " (125, 0.021927430330748943),\n",
            " (126, 0.020720399934556488),\n",
            " (127, 0.01645902909288382),\n",
            " (128, 0.005475900777155816),\n",
            " (129, 0.012489540038389958),\n",
            " (130, 0.018708398105755943),\n",
            " (131, 0.02764927610212525),\n",
            " (132, 0.014341068514749629),\n",
            " (133, 0.006997868061673282),\n",
            " (134, 0.009584739746453831),\n",
            " (135, 0.019924988409694925),\n",
            " (136, 0.03679991060464755),\n",
            " (137, 0.016238324452476725),\n",
            " (138, 0.03615935634609923),\n",
            " (139, 0.015872829362203786),\n",
            " (140, 0.01842800510827528),\n",
            " (141, 0.03313535820341334),\n",
            " (142, 0.023019949735017906),\n",
            " (143, 0.012934616123670433),\n",
            " (144, 0.032793995418377506),\n",
            " (145, 0.03982093450123227),\n",
            " (146, 0.02295091551691401),\n",
            " (147, 0.04066704217717456),\n",
            " (148, 0.019528534528041142),\n",
            " (149, 0.010323032305683912),\n",
            " (150, 0.006738252313156624),\n",
            " (151, 0.02646425063060505),\n",
            " (152, 0.040477854307666164),\n",
            " (153, 0.0087966665444789),\n",
            " (154, 0.06440869964375207),\n",
            " (155, 0.04098195830439138),\n",
            " (156, 0.04197779776861323),\n",
            " (157, 0.025140854095140077),\n",
            " (158, 0.02866197042751736),\n",
            " (159, 0.04526103763498415),\n",
            " (160, 0.02623064922535046),\n",
            " (161, 0.016074696391377416),\n",
            " (162, 0.026326086270674214),\n",
            " (163, 0.00957368689008181),\n",
            " (164, 0.012751408654978641),\n",
            " (165, 0.13110173692216798),\n",
            " (166, 0.02333316696516774),\n",
            " (167, 0.14694274707395796),\n",
            " (168, 0.02731485544192585),\n",
            " (169, 0.006649404113123216),\n",
            " (170, 0.024235468837489515),\n",
            " (171, 0.01227788181977211),\n",
            " (172, 0.018426259160709415),\n",
            " (173, 0.03648743709264792),\n",
            " (174, 0.03132045938826996),\n",
            " (175, 0.03445421571553568),\n",
            " (176, 0.016741735541476666),\n",
            " (177, 0.008020923432785116),\n",
            " (178, 0.02324955311779305),\n",
            " (179, 0.013757286152530334),\n",
            " (180, 0.01929259114516039),\n",
            " (181, 0.026890299394797906),\n",
            " (182, 0.00941336452113571),\n",
            " (183, 0.021825404699993174),\n",
            " (184, 0.007806975411095122),\n",
            " (185, 0.02489779735924498),\n",
            " (186, 0.04563897643694485),\n",
            " (187, 0.02522400172016377),\n",
            " (188, 0.025195156350943736),\n",
            " (189, 0.011463410939650132),\n",
            " (190, 0.03725908764178105),\n",
            " (191, 0.006872166173720983),\n",
            " (192, 0.014746648612043936),\n",
            " (193, 0.013155749485967521),\n",
            " (194, 0.028618815948996883),\n",
            " (195, 0.08691293098157439),\n",
            " (196, 0.02378398631016881),\n",
            " (197, 0.008117941798273137),\n",
            " (198, 0.1947381029543602),\n",
            " (199, 0.007373827001933797),\n",
            " (200, 0.008531505257936207),\n",
            " (201, 0.02106967343123284),\n",
            " (202, 0.005707082331779772),\n",
            " (203, 0.015212670894658463),\n",
            " (204, 0.0424981590241747),\n",
            " (205, 0.00700050866468498),\n",
            " (206, 0.0688616795838005),\n",
            " (207, 0.02095682343947038),\n",
            " (208, 0.019901778790792756),\n",
            " (209, 0.03424492250154886),\n",
            " (210, 0.024793497394802973),\n",
            " (211, 0.013273564819571464),\n",
            " (212, 0.014075143871358942),\n",
            " (213, 0.006895580424877477),\n",
            " (214, 0.031568359227347714),\n",
            " (215, 0.030847746110855095),\n",
            " (216, 0.0322691580661546),\n",
            " (217, 0.13360023096422025),\n",
            " (218, 0.014395763950182393),\n",
            " (219, 0.08037348195688707),\n",
            " (220, 0.06216049523534005),\n",
            " (221, 0.02358464153939847),\n",
            " (222, 0.07421719434372125),\n",
            " (223, 0.06980090154907437),\n",
            " (224, 0.04963669673355857),\n",
            " (225, 0.007661802330422432),\n",
            " (226, 0.007809906805211396),\n",
            " (227, 0.012189649341132779),\n",
            " (228, 0.006047454090240341),\n",
            " (229, 0.0388981710711509),\n",
            " (230, 0.06784636740653494),\n",
            " (231, 0.012143341744080863),\n",
            " (232, 0.024978069671992027),\n",
            " (233, 0.014681281530826672),\n",
            " (234, 0.01116626153950313),\n",
            " (235, 0.1892047399954708),\n",
            " (236, 0.009341573378356621),\n",
            " (237, 0.06477059880651459),\n",
            " (238, 0.10474562238210733),\n",
            " (239, 0.014604381824206045),\n",
            " (240, 0.08911270248130905),\n",
            " (241, 0.005413248069982572),\n",
            " (242, 0.023970650977710194),\n",
            " (243, 0.010009088082833571),\n",
            " (244, 0.008120993288901453),\n",
            " (245, 0.009974116425872141),\n",
            " (246, 0.0368748993769079),\n",
            " (247, 0.040580904237458366),\n",
            " (248, 0.01747167338963999),\n",
            " (249, 0.027679724693435687),\n",
            " (250, 0.011442447972571324),\n",
            " (251, 0.017780959818293925),\n",
            " (252, 0.011293924139444366),\n",
            " (253, 0.04563897643694485),\n",
            " (254, 0.03348814991596601),\n",
            " (255, 0.02144143741371448),\n",
            " (256, 0.021151299148169548),\n",
            " (257, 0.03521099653293449),\n",
            " (258, 0.01398164383800428),\n",
            " (259, 0.00799685752182444),\n",
            " (260, 0.02553559143245922),\n",
            " (261, 0.01634325719437088),\n",
            " (262, 0.006511812416451606),\n",
            " (263, 0.013620143965252459),\n",
            " (264, 0.01089958429629452),\n",
            " (265, 0.05340446815407385),\n",
            " (266, 0.009496755358686966),\n",
            " (267, 0.014266487371912996),\n",
            " (268, 0.038280024426080514),\n",
            " (269, 0.012478818640332635),\n",
            " (270, 0.017794695947621272),\n",
            " (271, 0.009759992379784357),\n",
            " (272, 0.06345812533483305),\n",
            " (273, 0.03405102237697048),\n",
            " (274, 0.050832284017794306),\n",
            " (275, 0.10638206208464672),\n",
            " (276, 0.08175471965658158),\n",
            " (277, 0.025195156350943736),\n",
            " (278, 0.07109698905668474),\n",
            " (279, 0.02098224563862438),\n",
            " (280, 0.11385135562496364),\n",
            " (281, 0.019771890945645586),\n",
            " (282, 0.015415924741676629),\n",
            " (283, 0.01598994490196798),\n",
            " (284, 0.07461367115365306),\n",
            " (285, 0.008609129712372942),\n",
            " (286, 0.010595436392166674),\n",
            " (287, 0.00986249210577505),\n",
            " (288, 0.030517103663029812),\n",
            " (289, 0.024687717802929172),\n",
            " (290, 0.47244040458460673),\n",
            " (291, 0.019840055929390553),\n",
            " (292, 0.0424977881270482),\n",
            " (293, 0.01110769730871408),\n",
            " (294, 0.1439658212533441),\n",
            " (295, 0.04297987086922595),\n",
            " (296, 0.02264941316825871),\n",
            " (297, 0.007302102333385353),\n",
            " (298, 0.06486728332221627),\n",
            " (299, 0.08866771168601092),\n",
            " (300, 0.0355043571577941),\n",
            " (301, 0.028913261377072137),\n",
            " (302, 0.14388131294017298),\n",
            " (303, 0.03348814991596601),\n",
            " (304, 0.015526274200408705),\n",
            " (305, 0.02238454008150115),\n",
            " (306, 0.012592140331191123),\n",
            " (307, 0.015931165799314157),\n",
            " (308, 0.010314925335964549),\n",
            " (309, 0.07906284209302189),\n",
            " (310, 0.008185353851459971),\n",
            " (311, 0.018577807583822378),\n",
            " (312, 0.0424981590241747),\n",
            " (313, 0.01014660998547707),\n",
            " (314, 0.017773444332481545),\n",
            " (315, 0.030285734953889212),\n",
            " (316, 0.03443083979190025),\n",
            " (317, 0.00560495256129302),\n",
            " (318, 0.039963591920998964),\n",
            " (319, 0.017826683090912787),\n",
            " (320, 0.014987256089130657),\n",
            " (321, 0.0590623758866667),\n",
            " (322, 0.027053936158305578),\n",
            " (323, 0.006656979868113169),\n",
            " (324, 0.058705700112809074),\n",
            " (325, 0.029387291380825086),\n",
            " (326, 0.04633450988988755),\n",
            " (327, 0.011049572525066),\n",
            " (328, 0.006357153132813939),\n",
            " (329, 0.01527390606619483),\n",
            " (330, 0.021625014082616273),\n",
            " (331, 0.016835177070917962),\n",
            " (332, 0.005920065515249117),\n",
            " (333, 0.011193441247598206),\n",
            " (334, 0.03725008142204035),\n",
            " (335, 0.027959165779549433),\n",
            " (336, 0.013644383943770103),\n",
            " (337, 0.036133461132951676),\n",
            " (338, 0.01903859432909743),\n",
            " (339, 0.022129596722214633),\n",
            " (340, 0.01659453474408978),\n",
            " (341, 0.034162158215307104),\n",
            " (342, 0.01701588258704686),\n",
            " (343, 0.030621078616654484),\n",
            " (344, 0.02131717719673976),\n",
            " (345, 0.033902484441232776),\n",
            " (346, 0.10797710765528043),\n",
            " (347, 0.025681475383693315),\n",
            " (348, 0.03373408196413776),\n",
            " (349, 0.02514115377684942),\n",
            " (350, 0.04331430358403721),\n",
            " (351, 0.01610885833807972),\n",
            " (352, 0.034340239825061965),\n",
            " (353, 0.019113922723628437),\n",
            " (354, 0.014942949721285645),\n",
            " (355, 0.014668078738387515),\n",
            " (356, 0.015931165799314157),\n",
            " (357, 0.012393577517609701),\n",
            " (358, 0.05447608271895487),\n",
            " (359, 0.038005859226951086),\n",
            " (360, 0.029339913808914028),\n",
            " (361, 0.018054369721695603),\n",
            " (362, 0.031021340802536955),\n",
            " (363, 0.014764291647549613),\n",
            " (364, 0.0070508519129759825),\n",
            " (365, 0.009330861864052672),\n",
            " (366, 0.011148269960848993),\n",
            " (367, 0.016625145277017313),\n",
            " (368, 0.007365517104273124),\n",
            " (369, 0.01318313633438673),\n",
            " (370, 0.056897125494086064),\n",
            " (371, 0.024587114242592575),\n",
            " (372, 0.030135094326590256),\n",
            " (373, 0.017543445527211904),\n",
            " (374, 0.019422240474962934),\n",
            " (375, 0.016625145277017313),\n",
            " (376, 0.02453381455114333),\n",
            " (377, 0.012548774458042417),\n",
            " (378, 0.04485094961876033),\n",
            " (379, 0.007011080087492298),\n",
            " (380, 0.03808983391918081),\n",
            " (381, 0.030410100845913994),\n",
            " (382, 0.16886250813687922),\n",
            " (383, 0.03869928858607272),\n",
            " (384, 0.032213467297135756)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA with tfidf\n",
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
      ],
      "metadata": {
        "id": "jH2gH0rEq3lG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} \\nWord: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEtptaakrMzQ",
        "outputId": "086ffe8f-aedc-42d2-fc42-cc0114e99154"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Word: 0.002*\"cluster\" + 0.002*\"imag\" + 0.002*\"kernel\" + 0.002*\"graph\" + 0.002*\"tree\" + 0.002*\"polici\" + 0.002*\"label\" + 0.002*\"posterior\" + 0.002*\"bayesian\" + 0.002*\"classifi\"\n",
            "Topic: 1 \n",
            "Word: 0.004*\"polici\" + 0.003*\"kernel\" + 0.003*\"action\" + 0.003*\"agent\" + 0.002*\"tree\" + 0.002*\"graph\" + 0.002*\"reward\" + 0.002*\"label\" + 0.002*\"cluster\" + 0.002*\"imag\"\n",
            "Topic: 2 \n",
            "Word: 0.003*\"imag\" + 0.002*\"layer\" + 0.002*\"kernel\" + 0.002*\"tree\" + 0.002*\"cluster\" + 0.002*\"graph\" + 0.002*\"deep\" + 0.002*\"loss\" + 0.001*\"neuron\" + 0.001*\"convex\"\n",
            "Topic: 3 \n",
            "Word: 0.003*\"neuron\" + 0.003*\"graph\" + 0.002*\"cluster\" + 0.002*\"spike\" + 0.002*\"cell\" + 0.002*\"rank\" + 0.002*\"edg\" + 0.002*\"tree\" + 0.001*\"layer\" + 0.001*\"imag\"\n",
            "Topic: 4 \n",
            "Word: 0.003*\"cluster\" + 0.003*\"tree\" + 0.002*\"imag\" + 0.002*\"layer\" + 0.002*\"graph\" + 0.002*\"neuron\" + 0.002*\"node\" + 0.002*\"posterior\" + 0.002*\"nod\" + 0.002*\"infer\"\n",
            "Topic: 5 \n",
            "Word: 0.003*\"polici\" + 0.002*\"cluster\" + 0.002*\"queri\" + 0.002*\"imag\" + 0.002*\"label\" + 0.002*\"document\" + 0.002*\"layer\" + 0.002*\"submodular\" + 0.002*\"risk\" + 0.002*\"latent\"\n",
            "Topic: 6 \n",
            "Word: 0.005*\"polici\" + 0.004*\"reward\" + 0.004*\"regret\" + 0.003*\"neuron\" + 0.003*\"action\" + 0.003*\"bandit\" + 0.002*\"cluster\" + 0.002*\"spike\" + 0.002*\"arm\" + 0.002*\"agent\"\n",
            "Topic: 7 \n",
            "Word: 0.006*\"neuron\" + 0.005*\"spike\" + 0.003*\"cell\" + 0.002*\"synapt\" + 0.002*\"synaps\" + 0.002*\"fire\" + 0.002*\"reward\" + 0.002*\"imag\" + 0.002*\"motion\" + 0.002*\"polici\"\n",
            "Topic: 8 \n",
            "Word: 0.005*\"kernel\" + 0.003*\"imag\" + 0.002*\"cluster\" + 0.002*\"label\" + 0.002*\"loss\" + 0.002*\"convex\" + 0.002*\"rank\" + 0.002*\"layer\" + 0.002*\"classifi\" + 0.002*\"dataset\"\n",
            "Topic: 9 \n",
            "Word: 0.003*\"neuron\" + 0.003*\"polici\" + 0.002*\"imag\" + 0.002*\"rank\" + 0.002*\"kernel\" + 0.002*\"action\" + 0.002*\"convex\" + 0.002*\"layer\" + 0.002*\"tensor\" + 0.001*\"gradient\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lda with bag of words\n",
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "metadata": {
        "id": "ihhgpUscrOlc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_GyT5rmr1WY",
        "outputId": "9981e33e-f1be-4d10-8338-464076533ad2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.006*\"memori\" + 0.006*\"neuron\" + 0.005*\"dynam\" + 0.005*\"topic\" + 0.005*\"action\" + 0.005*\"activ\" + 0.005*\"spars\" + 0.004*\"cost\" + 0.004*\"bind\" + 0.004*\"sequenc\"\n",
            "Topic: 1 \n",
            "Words: 0.016*\"label\" + 0.010*\"graph\" + 0.007*\"imag\" + 0.005*\"edg\" + 0.005*\"infer\" + 0.004*\"constraint\" + 0.004*\"cluster\" + 0.004*\"prior\" + 0.004*\"nois\" + 0.004*\"dataset\"\n",
            "Topic: 2 \n",
            "Words: 0.014*\"cluster\" + 0.008*\"unit\" + 0.007*\"infer\" + 0.007*\"tree\" + 0.006*\"activ\" + 0.006*\"neuron\" + 0.005*\"likelihood\" + 0.005*\"prior\" + 0.004*\"posterior\" + 0.004*\"bind\"\n",
            "Topic: 3 \n",
            "Words: 0.027*\"imag\" + 0.006*\"layer\" + 0.006*\"infer\" + 0.005*\"visual\" + 0.005*\"filter\" + 0.005*\"dataset\" + 0.004*\"pixel\" + 0.004*\"gradient\" + 0.004*\"deep\" + 0.004*\"cell\"\n",
            "Topic: 4 \n",
            "Words: 0.011*\"layer\" + 0.009*\"imag\" + 0.008*\"gradient\" + 0.008*\"loss\" + 0.007*\"classifi\" + 0.007*\"dataset\" + 0.007*\"convex\" + 0.007*\"classif\" + 0.006*\"rank\" + 0.006*\"word\"\n",
            "Topic: 5 \n",
            "Words: 0.007*\"neuron\" + 0.006*\"activ\" + 0.005*\"norm\" + 0.005*\"nois\" + 0.005*\"theorem\" + 0.004*\"spike\" + 0.004*\"gradient\" + 0.004*\"imag\" + 0.004*\"cluster\" + 0.004*\"layer\"\n",
            "Topic: 6 \n",
            "Words: 0.017*\"kernel\" + 0.006*\"rank\" + 0.005*\"graph\" + 0.005*\"infer\" + 0.005*\"theorem\" + 0.005*\"classif\" + 0.005*\"loss\" + 0.004*\"bound\" + 0.004*\"bind\" + 0.004*\"convex\"\n",
            "Topic: 7 \n",
            "Words: 0.008*\"graph\" + 0.007*\"loss\" + 0.007*\"theorem\" + 0.006*\"convex\" + 0.005*\"imag\" + 0.005*\"nois\" + 0.005*\"bound\" + 0.005*\"bind\" + 0.004*\"label\" + 0.004*\"stochast\"\n",
            "Topic: 8 \n",
            "Words: 0.009*\"kernel\" + 0.008*\"imag\" + 0.006*\"signal\" + 0.005*\"respons\" + 0.004*\"neuron\" + 0.004*\"gradient\" + 0.004*\"detect\" + 0.004*\"dynam\" + 0.004*\"nois\" + 0.003*\"human\"\n",
            "Topic: 9 \n",
            "Words: 0.015*\"polici\" + 0.010*\"action\" + 0.009*\"reward\" + 0.007*\"agent\" + 0.006*\"bind\" + 0.006*\"regret\" + 0.006*\"bound\" + 0.006*\"theorem\" + 0.006*\"cluster\" + 0.005*\"cost\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "from gensim.models import CoherenceModel\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=preprocessed_paper_text, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJUrlrBKr6cG",
        "outputId": "7f37b869-d529-4330-e7d0-6119cfe9f922"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.2601694572275357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_lda2 = CoherenceModel(model=lda_model, texts=preprocessed_paper_text, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Pht7Dyt63c",
        "outputId": "1be52edf-996c-49c0-9ae0-6d1803fabfce"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.3087544199367178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since lda with bag of words works better we'll perform model tuning on it\n",
        "# lda with bag of words\n",
        "lda_model2 = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=10, workers=4,per_word_topics = True, chunksize = 2500)\n",
        "for idx, topic in lda_model2.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHLGTtzUvtl6",
        "outputId": "fbbd673c-5bdb-4b32-eb16-e1c4163ff9a2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.019*\"gradient\" + 0.019*\"loss\" + 0.016*\"bind\" + 0.012*\"bound\" + 0.012*\"stochast\" + 0.012*\"convex\" + 0.009*\"regret\" + 0.009*\"updat\" + 0.009*\"theorem\" + 0.008*\"onlin\"\n",
            "Topic: 1 \n",
            "Words: 0.016*\"graph\" + 0.014*\"label\" + 0.012*\"word\" + 0.010*\"infer\" + 0.009*\"edg\" + 0.008*\"queri\" + 0.008*\"node\" + 0.007*\"nod\" + 0.007*\"tree\" + 0.005*\"topic\"\n",
            "Topic: 2 \n",
            "Words: 0.029*\"kernel\" + 0.013*\"label\" + 0.013*\"classif\" + 0.012*\"classifi\" + 0.010*\"dataset\" + 0.008*\"rank\" + 0.008*\"margin\" + 0.008*\"regress\" + 0.007*\"tree\" + 0.006*\"regular\"\n",
            "Topic: 3 \n",
            "Words: 0.010*\"signal\" + 0.008*\"respons\" + 0.008*\"nois\" + 0.007*\"unit\" + 0.007*\"filter\" + 0.006*\"activ\" + 0.006*\"subject\" + 0.006*\"prior\" + 0.005*\"speech\" + 0.005*\"visual\"\n",
            "Topic: 4 \n",
            "Words: 0.033*\"neuron\" + 0.021*\"spike\" + 0.011*\"activ\" + 0.009*\"cell\" + 0.008*\"dynam\" + 0.008*\"synapt\" + 0.008*\"circuit\" + 0.007*\"fire\" + 0.006*\"synaps\" + 0.005*\"simul\"\n",
            "Topic: 5 \n",
            "Words: 0.038*\"imag\" + 0.024*\"layer\" + 0.011*\"unit\" + 0.009*\"deep\" + 0.008*\"convolut\" + 0.007*\"hide\" + 0.007*\"recognit\" + 0.007*\"pixel\" + 0.006*\"transform\" + 0.006*\"architectur\"\n",
            "Topic: 6 \n",
            "Words: 0.025*\"polici\" + 0.023*\"action\" + 0.017*\"reward\" + 0.015*\"agent\" + 0.010*\"game\" + 0.009*\"decis\" + 0.008*\"reinforc\" + 0.006*\"player\" + 0.006*\"strategi\" + 0.006*\"dynam\"\n",
            "Topic: 7 \n",
            "Words: 0.022*\"imag\" + 0.007*\"detect\" + 0.007*\"human\" + 0.007*\"motion\" + 0.007*\"visual\" + 0.007*\"trajectori\" + 0.006*\"video\" + 0.006*\"shape\" + 0.006*\"polici\" + 0.005*\"robot\"\n",
            "Topic: 8 \n",
            "Words: 0.045*\"cluster\" + 0.013*\"graph\" + 0.011*\"distanc\" + 0.008*\"partit\" + 0.008*\"densiti\" + 0.008*\"mixtur\" + 0.006*\"manifold\" + 0.005*\"metric\" + 0.005*\"dataset\" + 0.005*\"dimens\"\n",
            "Topic: 9 \n",
            "Words: 0.012*\"spars\" + 0.011*\"norm\" + 0.011*\"theorem\" + 0.011*\"rank\" + 0.010*\"convex\" + 0.008*\"regular\" + 0.006*\"matric\" + 0.006*\"tensor\" + 0.006*\"bound\" + 0.006*\"constraint\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_lda2 = CoherenceModel(model=lda_model2, texts=preprocessed_paper_text, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda2.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMMG4XBx0G-s",
        "outputId": "067553fc-3142-4fcb-ae68-f4a345b58723"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.5035815573915146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UOlwQj5R299A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}